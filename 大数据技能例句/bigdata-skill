# 大数据简历技能列表

## Java基础
• 1、掌握Java，熟练掌握Shell/Python语言，具备良好的面向对象和函数式编程思想，了解常用设计模式；

• 2、扎实的Java语言基础，熟悉10，多线程，集合等，深刻理解面向对象的编程思想和设计模式，并熟练恰当的运用到开发实战当中；

• 3、精通使用Java主流开发框架和工具：Spring、Hibernate、Mybatis、 SpringMVC、 SpringBoot、Tomcat、WebLogic等；

• 4、精通HTTP协议，熟悉websocket开发，了解ProtoBuf协议，了解Spring Cloud微服务框架；

• 5、精通常用数据库MySQL、MongoDB、Redis，熟悉Linux系统常用命令、linux下的系统部署和配置，熟悉web系统常见的安全性问题及解决方案；

• 6、熟悉计算机操作系统、网络编程、分布式等基本原理；

• 7、深刻理解计算机原理，有良好的数据结构和扎实的编程能力；

• 8、熟悉并行计算或者分 布式计算原理，熟悉高并发、高稳定性、可线性扩展、海量数据的系统特点和技术方案；

• 9、精通HTTP、TCP/P协议，网络编程；熟悉Linux操作系统原理，常用工具；

• 10、有高并发、大容量后台服务系统设计经验；

• 11、熟悉spring cloud。对k8s，微服务，服务治理和service mesh有经验。

• 12、熟悉内核源码、熟悉 k8s-operator、CRD、CN、CSI 等组件/插件工作原理，能针对特定的业务场景进行二次开发。

• 13、精通java技术，熟悉JVM、分布式、多线程、高并发等等原理和应用；

• 14、熟练操作Linux系统及linux下主流数据库 (Oracle、mysql、hbase） 等操作，熟练使用sql。

• 15、JAVA基础扎实，包括JVM、IO、多线程、并发、网络等，深刻理解面向对象、设计模式，精通J2EE、SOA等相关技术

• 16、熟练使用常用的JAVA技术框架，并对JAVA Web的各种主流框架如Spring、Spring Boot、MyBatis等有深入的应用和优化经验

• 17、熟悉分布式系统的设计和应用，熟悉数据库、缓存、消息队列、RPC等内部机制

• 18、熟悉多线程、高性能程序设计和编码；有一定的数据结构和算法思维；

## 数据采集
• 1、了解数据采集和埋点流程，具备日志流量数据模型能力。

• 2、熟悉大数据产品和技术，熟悉ETL的开发和流程优化，对数据采集、数据集成、数据开发、数据分析等大数据领域有实战经验；

• 3、熟练应用FileBeat、LogStash、Log4J等日志采集工具。

• 4、熟练使用datax、canal等数据同步工具对数据进行全量和增量同步。

• 5、能够使用FlinkCDC、Debezium等工具实时同步数据，构建实时数仓。

• 6、熟练掌握大数据组件包括但不限于数据采集(Canal或Debezium)StarRocks、Flink、Kafka等。

## 数据计算
• 1、 熟悉Spark、 ElasticSearch、 Flink、Kafka、Trino、Hadoop、Alluxio等常用组件的使用，了解组件的实现原理，熟悉分布式系统架构基本理论；

• 2、熟悉Hadoop、Hive、HBase、Spark、Flink、Kafka等常用组件的使用，了解至少一种组件的实现原理；

• 3、有较强的开发能力，熟练应用常用的BI工具，如Tableau、Power Bl等，熟悉 Hadoop、Hive、Spark、Flink 等流数据的开发，具备 SQL、Python 语言的开发能力；

• 4、熟悉一种或多种主流开源大数据平台组件，如Spark、Kafka、Hbase、Hive、Flume、Flink等

• 5、熟悉整个大数据的完整处理流程（数据的采集、清洗、预处理、存储、分析挖掘、机器学习和数据可视化等）有完整的大数据项目设计、开发及部署经验；

• 6、熟悉Kafka/Flink/Druid/Hbase/Doris等实时计算引擎、组件的开发和使用；

• 7、熟练使用Flink、Clickhouse、Hive、Spark等大数据开发语言和框架；

• 8、对Hadoop、Flink、Spark、 Lucene等开源项目有大规模应用经验。

• 9、有系统性的海量数据性能处理经验，具备数据仓库架构设计能力，具备实时＋离线数据处理能力，有离线＋实时数据调优能力。

• 10、xx年以上TB级数据规模大型项目架构/开发/调优经验，具有行业数据平台数据架构和开发工作经验；

• 11、熟悉常见的算法和数据结构，熟练设计数据模型、ETL设计、Cube多维建模、OLAP开发、报表开发等；

• 12、熟练使用大数据处理框架 (Hadoop /Hive/Spark/Impala/Kylin）相关技术；

• 13、熟悉流式计算引擎，对相关框架(Kafka/ Storm/SparkStreaming/Flink)有实际应用经验；

• 14、有大数据系统架构设计及开发、重大模块设计及开发 经验，深入理解大数据计算框架，对大数据的技术趋势有 较深的理解；

• 15、精通Hadoop, Spark, Flink, Kafka, ElasticSearch等常用大数据处理组件，熟练使用Spark或Fink等组件进行PB级的实时和离线的数据开发，具备各种组件之问配合调优经验，熟悉Hadoop， Spark内核，具备源码级调优经验；

• 16、熟悉Hadoop 生态，包括 HDFS/Mapreduce/Hive/Spark/Hbase，熟悉 Kafka 等实时开源工具并有项目经验；

• 17、熟悉大数据产品生态圈包括但不限于Hive、HBase、Kafaka、Flink、ES、Spark等，善于容量规划、架构设计和性能优化并有丰富实战经验；

• 18、熟练掌握storm、Flink或spark流计算开发技术，熟悉hbase 和MPP数据库，有实时数据应用开发经验。

## 数据仓库
• 1、熟悉Oracle、Mysql、Postgresal Clickhouse、Flink等主流数据仓库模型设计之一，有丰富的SQL性能调优经验；

• 2、熟悉数据统计系统或BI/DW原理和实施，具备数据仓库、数据集成、多维数据仓库设计、开发、架构经验；

• 3、熟悉分布式系统的基本理论，有大数据平台的架构设计、开发和调试经验；

• 4、对时序数据库OpenTSDB、InfluxDB、Druid、Beringer等有使用和研究经验。

• 5、有大型数据仓库架构、ETL设计、数据中台设计、数据治理的相关经验

• 6、熟练掌握Hive/MapReduce/ Spark/Flink /kafka/durid/presto等分布式计算系统;

• 7、有基于SQL及No-SQL数据库，数据仓库的设计建设经验。

• 8、拥有数仓建模、ETL数据抽取、OLAP分析开发等经验。

• 9、具备数据模型设计能力，了解业界互联网常用数据模型设计方法，具备OLAP模型设计和解决方案能力。

• 10、熟悉业界主流大数据技术框架，如查询引擎Presto/Impala和消息队列kafka/pulsar，深入了解其技术原理，有相关的bug修复、性能优化经验。

• 11、熟悉数据仓库理论和技术体系，熟练掌握SQL/Hive/MapReduce/ Spark/Flink等大规模数据处理技术；

• 12、精通MySQL、MongoDB 等数据库的开发设计，及数据库系统性能优化，SQL性能优化。有海量数据处理经验；

• 13、熟悉hadoop框架和hive原理，理解大数据调度的原理。

• 14、深入理解数据仓库建设理论与方法、具备丰富的实践经验。精通SQL，有海量数据处理经验。

• 15、深入理解主流的OLAP项目架构设计方案和原理，如：Kylin、lmpala等；

• 16、熟悉分布式系统的设计和应用，了解一般的数据库原理(sm树，B+树，列存，全文倒排索引等）；

• 17、至少熟悉分布式KV存储，Flink, Trino, PostgreSQL等分布式存储系统或者大数据开源组件的一种。

• 20、精通数据仓库方法论，能够根据企业实际情况设计合理的数据仓库架构。

• 21、熟悉数据湖Delta Lake，Iceberg，Hudi，并有一定实践优化经验。

• 22、熟悉数据湖Delta Lake，Iceberg，Hudi数据湖技术，并阅读过相关代码。

## 数据治理
• 1、精通大数据计算、存储、tableformat、元数据方向中的一个或多个领域。对Spark/Alink/ presto/alluxio，iceberg/hudi, hive metastore/a6n/metacat 多个开源项目有深度理解。

• 2、熟悉cloud native相关技术，K8s,etcd, contour等。

• 3、熟悉大数据serverless相关技术，livy，genie。

• 4、具有良好的学习能力、沟通能力、团队合作意识，强烈的责任心与主动性。

• 5、精通java，熟悉spring cloud；对微服务，服务治理或者service mesh有很深的经验。

• 6、有分布式机器学习框架经验、大数据与机器学习结合平台研发经验。

• 7、有公有云大数据平台产品研发经验和基于公有云搭建平台级云原生数据平台经验。

• 8、熟悉数据治理方法论，对数据建模、数据质量、数据资产、元数据管理等有实战经验。

• 9、熟悉大规模数据挖掘、机器学习、深度学习等相关技术，对分类聚类等机器学习算法、TensorFlow / Caffe等深度学习框架有实战经验。

• 10、有较为系统的海量数据高性能处理经验，在大数据管理与治理有一定成功产品化经验。

• 11、熟悉数据仓库架构和数据治理，熟悉开源hadoop/hive分布式大数据处理平台，熟悉MapReduce/spark等开发框架。

• 12、xx年以上数据仓库领域经验，熟悉数据仓库模型设计与ETL开发经验，掌握Kimball的维度建模设计方法，具备海量数据加工处理 （ETL）相关经验，能灵活运用SQL

• 13、熟悉数据仓库领域知识和技能，包括但不局限于：主数据管理、元数据管理、数据开发测试工具与方法、数据质量

• 14、掌握数据质量管理方法论、评估模型设计、质量报表设计，能够根据数据质量要求制定数据质量探查规则并进行实施；

数据中台
• 1、熟悉基本数据平台架构相关内容包括不限于：金融数据仓库建模，BI工具、规则引擎、数据同步工具等

• 2、有负责或参与安全与风控相关数据的体系化建设的经验，按照OneData数据规范，构建数据仓库、元数据、质量体系，有效的管理和组织海量的数据。

• 3、较为丰富的数据仓库及数据平台的架构经验，熟悉数据仓库建模及ETL设计开发。

• 4、有参与打造数据中台内容的规划、设计、开发工作，实现高质量数据的互通与共享的经验。

• 5、有参与数据模型体系构建及数据主题设计和开发，搭建离线、近线、实时数据公共层的经验。

• 6、能够构建非结构化数据体系，进行网络数据爬取，数据清洗，特征挖掘，统计分析，并结合应用场景实现落地。

• 7、深入理解Hacoop，及各种大数据计算框架，熟练使用impala、Kudu，有lmpala、Kudu优化经验；

• 8、掌握常用的数据建模理论、数据仓库分层架构、模型设计、元数据管理及数据质量管理。

• 9、了解数据知识体系：对数据资产，数据生命周期、数据质量管控有相关经验。

• 10、熟悉数据库模型设计方法和规范，能使用数据建模软件DataBlaue或PowerDesign或Wrwin，独立开展数据建模；

• 11、有数据平台建设经验；熟悉lnfomatic、Kettle等ETL产品者；有过独立设计与开发数据中台、数据仓库或ETL工具产品开发经验。

• 12、具有大数据集群的架构思维，能够设计合理高效的大数据方案；

• 13、有数仓分层、数据服务DataApi平台建设经验，有实战开发和调优经验。

## 人工智能
• 1、具有大数据计算和Al模型训练/推理结合的经验。

• 2、熟悉机器视觉、自然语言处理、图像处理、模式识别、运筹优化、机器学习、深度学习。

• 3、熟悉常用的机器学习算法，如GBDT/LR/SVM，有深度学习方向、图数据挖掘经验方向。

• 4、了解分布式深度学习相关技术（比如 MPI Allreduce、Parameter Server 等）以及常用框架（比如 OpenMPI、 NCCL 等）

• 5、在计算机视觉、图像处理等领域有深入认识，并了解主要算法的原理和瓶颈；

• 6、动手能力强，有扎实的Python、C++ 编程能力，熟悉TensorFlow、PyTorch、OpenCV等库；

• 7、具有熟练的英文文献阅读能力，较强的论文复现能力；

• 8、熟练使用pytorch, tensorflow， caffe等深度学习训练框架；

• 9、深度了解、熟悉各种类型模型特点，如分类(ResNet、MobileNet)，检测 (YOLO/SSD/Faster/Mask RCNN)，分割 (DeepLab,Unet) ，NLP(Transformer /Bert/LSTM/GPU)，推荐(Wide and Deep) ;

• 10、对深度学习模型训练有大量实践经验，如超参调整、正则化等技巧；

• 11、对TensorFlow/PyTorch实现原理熟悉，有大量使用经验；

• 12、对常见公共数据集有了解和使用经验，如lmageNetPascalvoc、COCO等；

• 13、对深度学习推理优化技术和算法有深刻理解和实践经验，如量化、剪枝、知识蒸馏、Winograd变换等；
